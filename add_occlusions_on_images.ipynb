{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcbcb5-c15f-4ab3-aa67-3443d2b579d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import dlib\n",
    "import cv2\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# location of the model (path of the model).\n",
    "model_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "# catalogues (global values)\n",
    "face_image_catalogue = './samples'\n",
    "occ_catalogue = './occ'\n",
    "result_catalogue = './results'\n",
    "\n",
    "# filename ending for images with synthetic occlusion applied\n",
    "synthetic_file_ext = ['_glass.', '_mask.','_cap.', '_sunglass.']\n",
    "\n",
    "# occlusions choices (filename.ext in the occ catalog, like 'glass.png')\n",
    "mask = 'mask.png'\n",
    "cap = ''\n",
    "glass = 'glass.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206b8ae-b776-408b-8b1e-2a04280bcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prining/log functions\n",
    "def print_message(error_message):\n",
    "    ''' Print all error messages from the program run '''\n",
    "    if not error_message:\n",
    "        print('None errors during occlusion masking')\n",
    "    else:\n",
    "        print('Number of files skipped (error):', len(error_message))\n",
    "        print('Errors detected during program run:', file=sys.stderr)\n",
    "        print(*error_message, sep=\"\\n\", file=sys.stderr)\n",
    "    return None\n",
    "\n",
    "\n",
    "def print_result(error_message, generated_images_count):\n",
    "    ''' Print overview of program run '''\n",
    "    print('Occlusion(s) added: ', end='')\n",
    "    if mask:\n",
    "        print('Mask ', end='')\n",
    "    if cap:\n",
    "        print('Cap ', end='')\n",
    "    if glass:\n",
    "        print('Glass', end='')\n",
    "    print('\\nNumber of synthetic images generated:', generated_images_count)\n",
    "\n",
    "    print_message(error_message)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c6b45-64ff-4bcc-8d0e-e81cb18e1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_area_of_rotated(width, height, angle):\n",
    "    '''\n",
    "    Given a rectangle of size wxh that has been rotated by 'angle' (in\n",
    "    radians), computes the width and height of the largest possible\n",
    "    axis-aligned rectangle (maximal area) within the rotated rectangle.\n",
    "    Original code by coproc from Stack Overflow, but adapted for this project\n",
    "    '''\n",
    "    if width <= 0 or height <= 0:\n",
    "      return 0,0\n",
    "\n",
    "    width_is_longer = (width >= height)\n",
    "    side_long, side_short = (width,height) if width_is_longer else (height,width)\n",
    "\n",
    "    # since the solutions for angle, -angle and 180-angle are all the same,\n",
    "    # if suffices to look at the first quadrant and the absolute values of sin,cos:\n",
    "    sin_a, cos_a = abs(math.sin(angle)), abs(math.cos(angle))\n",
    "    if side_short <= 2.*sin_a*cos_a*side_long or abs(sin_a-cos_a) < 1e-10:\n",
    "      # half constrained case: two crop corners touch the longer side,\n",
    "      #   the other two corners are on the mid-line parallel to the longer line\n",
    "      x = 0.5*side_short\n",
    "      return (x/sin_a,x/cos_a) if width_is_longer else (x/cos_a,x/sin_a)\n",
    "    else:\n",
    "      # fully constrained case: crop touches all 4 sides\n",
    "      cos_2a = cos_a*cos_a - sin_a*sin_a\n",
    "      return (width*cos_a - height*sin_a)/cos_2a, (height*cos_a - width*sin_a)/cos_2a\n",
    "\n",
    "def rotate_img(img, angle):\n",
    "    ''' Rotate given image by angle angle in range 0...360 degree.\n",
    "    Returns: rotated image '''\n",
    "    # dividing height and width by 2 to get the center of the image\n",
    "    height, width = img.shape[:2]\n",
    "    # get the center coordinates of the image to create the 2D rotation matrix\n",
    "    center = (width/2, height/2)\n",
    "\n",
    "    # using cv2.getRotationMatrix2D() to get the rotation matrix\n",
    "    rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=angle, scale=1)\n",
    "\n",
    "    return cv2.warpAffine(src=img, M=rotate_matrix, dsize=(width, height))\n",
    "\n",
    "\n",
    "def rotate_and_crop(img, angle, crop):\n",
    "    ''' rotate image\n",
    "    Parameters:\n",
    "        img: cv2 image matrix object\n",
    "        angle: in degree\n",
    "        crop: True cropping of the rotated image\n",
    "              False rotate and then crop image\n",
    "    '''\n",
    "    if not crop:\n",
    "        return rotate_img(img, angle)   # rotate only\n",
    "    else:\n",
    "        optimal_width, optimal_height = maximum_area_of_rotated(img.shape[1], img.shape[0],\n",
    "                                    math.radians(angle))\n",
    "        rotated = rotate_img(img, angle)\n",
    "        height, width, = rotated.shape[:2]\n",
    "        y1 = height//2 - int(optimal_height/2)\n",
    "        y2 = y1 + int(optimal_height)\n",
    "        x1 = width//2 - int(optimal_width/2)\n",
    "        x2 = x1 + int(optimal_width)\n",
    "\n",
    "        return rotated[y1:y2, x1:x2]\n",
    "\n",
    "def calculate_eye_center(detected_landmarks):\n",
    "    ''' Calculate center of each eye based on all 6 eye FaceLandmarks\n",
    "    returns:\n",
    "        lefteye_center (y,x), right_eye_center (y,x)\n",
    "    '''\n",
    "    # Left eye centre\n",
    "    left_eye_x = int((detected_landmarks.part(36).x + detected_landmarks.part(37).x +\n",
    "                      detected_landmarks.part(38).x + detected_landmarks.part(39).x +\n",
    "                      detected_landmarks.part(40).x + detected_landmarks.part(41).x)/ 6)\n",
    "    left_eye_y = int((detected_landmarks.part(36).y + detected_landmarks.part(37).y +\n",
    "                      detected_landmarks.part(38).y + detected_landmarks.part(39).y +\n",
    "                      detected_landmarks.part(40).y + detected_landmarks.part(41).y ) / 6)\n",
    "    # Right Eye centre\n",
    "    right_eye_x = int((detected_landmarks.part(42).x + detected_landmarks.part(43).x +\n",
    "                       detected_landmarks.part(44).x + detected_landmarks.part(45).x +\n",
    "                       detected_landmarks.part(46).x + detected_landmarks.part(47).x) / 6)\n",
    "    right_eye_y = int((detected_landmarks.part(42).y + detected_landmarks.part(43).y +\n",
    "                       detected_landmarks.part(44).y + detected_landmarks.part(45).y +\n",
    "                       detected_landmarks.part(46).y + detected_landmarks.part(47).y) / 6)\n",
    "\n",
    "    left_eye_center = (left_eye_y, left_eye_x)\n",
    "    right_eye_center = (right_eye_y, right_eye_x)\n",
    "\n",
    "    return (left_eye_center, right_eye_center)\n",
    "\n",
    "def rotate_face_image_angle(face_img, detected_landmarks):\n",
    "    ''' Calculate rotate angel of face image\n",
    "    return: angle: in range 0..360\n",
    "    '''\n",
    "\n",
    "    def get_angel (a, b, c):\n",
    "        ''' Calculate angel between 3 pojnts (2-dimensional '''\n",
    "        ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "        return ang + 360 if ang < 0 else ang\n",
    "\n",
    "    left_eye_center, right_eye_center = calculate_eye_center(\n",
    "        detected_landmarks)\n",
    "\n",
    "    right_eye_fixed = (right_eye_center[0], left_eye_center[1])\n",
    "\n",
    "    return get_angel(left_eye_center, right_eye_center, right_eye_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce6c46-8555-47a3-a567-f7ade456e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask_on_image(bg_img, mask_img, alpha_img, alpha_mask_img, x, y):\n",
    "    ''' Adding a mask onto face image\n",
    "    Parameters:\n",
    "        bg_img : Face image\n",
    "        mask_img : occlusion image\n",
    "        alpha_img : alpha notation of the mask\n",
    "        alpha_mask_img : mask of the image (alpha value)\n",
    "        x : X-coordinat for upper left corner of the occlusion\n",
    "        y : Y-coordinat for upper left corner of the occlusion\n",
    "    return:\n",
    "        image\n",
    "    '''\n",
    "    for c in range(0, 3):\n",
    "        bg_img[y:y+mask_img.shape[0], x:x+mask_img.shape[1], c] = (alpha_mask_img * mask_img[:, :, c] + alpha_img * bg_img[y:y+mask_img.shape[0], x:x+mask_img.shape[1], c])\n",
    "\n",
    "    return (bg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38277c04-58ba-4aee-b082-006ebdc5d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_landmarks_within_image (detected_landmarks, image, image_filename, error_message):\n",
    "    ''' Check if given landmarks are inside the image\n",
    "    Parameters\n",
    "    Returns: True: legal filename\n",
    "            False: not a legal face image name to be processed\n",
    "    '''\n",
    "\n",
    "    # Actual landmarks for testing\n",
    "    right_ear_x = detected_landmarks.part(0).x\n",
    "    right_ear_y = detected_landmarks.part(0).y\n",
    "    left_ear_x = detected_landmarks.part(16).x\n",
    "    left_ear_y = detected_landmarks.part(16).y\n",
    "    right_eye_y = detected_landmarks.part(19).y\n",
    "    left_eye_y = detected_landmarks.part(24).y\n",
    "    chin_x = detected_landmarks.part(8).x # Only test if mask occlusion is selected\n",
    "    chin_y = detected_landmarks.part(8).y\n",
    "\n",
    "    if ((right_ear_x < 0) or (right_ear_y < 0) or (right_ear_x > image.shape[1]) or (right_ear_y > image.shape[0])):\n",
    "        error_message.append('Image ' + image_filename +\n",
    "\n",
    "                             ' face Landmarks left ear is out of bounds (i.e. outside the face image)')\n",
    "        return False, error_message\n",
    "    if ((left_ear_x < 0) or (left_ear_y < 0) or (left_ear_x > image.shape[1]) or (left_ear_y > image.shape[0])):\n",
    "        error_message.append('Image ' + image_filename +\n",
    "\n",
    "                              ' face Landmarks right ear is out of bounds (i.e. outside the face image)')\n",
    "        return False, error_message\n",
    "    if (right_eye_y < 0) or (left_eye_y < 0):\n",
    "        error_message.append('Image ' + image_filename +\n",
    "\n",
    "                             ' face Landmarks eyes are out of bounds (i.e. outside the face image)')\n",
    "        return False, error_message\n",
    "    if mask:\n",
    "        if ((chin_x < 0) or (chin_y < 0) or (chin_x > image.shape[1]) ):\n",
    "            error_message.append('Image ' + image_filename +\n",
    "\n",
    "                                 ' face Landmark chin is out of bounds (i.e. outside the face image)')\n",
    "            return False, error_message\n",
    "    return True, error_message\n",
    "\n",
    "\n",
    "def check_if_face_from_front(detected_landmarks):\n",
    "    ''' Check if face image photo is taken from front\n",
    "        calculating the distance from the ear to the center of the eye (both sides)\n",
    "        if the ratio between the distance values exceeds the ratio, the routine returns False\n",
    "    return:\n",
    "        True: the face is from from (within limits) and\n",
    "        False: the face is from side\n",
    "    '''\n",
    "\n",
    "    ratio = 4 # Ratio between ear and eye (keft and right side)\n",
    "    # get center of eyes:\n",
    "    left_eye_center , right_eye_center = calculate_eye_center(detected_landmarks)\n",
    "\n",
    "    right_ear_x = detected_landmarks.part(0).x\n",
    "    left_ear_x = detected_landmarks.part(16).x\n",
    "    distance_left = left_eye_center[1] - right_ear_x\n",
    "    distance_right = left_ear_x - right_eye_center[1]\n",
    "\n",
    "    if distance_left < distance_right:\n",
    "        if (distance_right / distance_left) > ratio:\n",
    "           return False\n",
    "    if distance_left > distance_right:\n",
    "        if (distance_left / distance_right) >  ratio:\n",
    "           return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74e6d1-10da-4889-a5b8-c36c24679cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_glasses(face_img, mask, face_landmarks):\n",
    "    ''' Mask a glass occlusion on a face image\n",
    "    parameters:\n",
    "        img: face image\n",
    "        mask: occlusion\n",
    "        face_landmarks: landmarks with 68 points for the face\n",
    "    return:\n",
    "\n",
    "        the image with the occlusion\n",
    "    '''\n",
    "   \n",
    "\n",
    "    # positions of the landmarks of interest\n",
    "    right_ear_x = face_landmarks.part(0).x\n",
    "    left_ear_x = face_landmarks.part(16).x\n",
    "\n",
    "   \n",
    "\n",
    "    # calculate eye centers:\n",
    "    left_eye_center, right_eye_center = calculate_eye_center(face_landmarks)\n",
    "   \n",
    "\n",
    "    '''\n",
    "\n",
    "    Calculations:\n",
    "        image_mask_width: with of the mask area in then image\n",
    "        mask_width: width of the mask (x-direction)\n",
    "\n",
    "        mask_scale: Scaling of the mask before putting it on the face image\n",
    "       \n",
    "\n",
    "        All glasses to be put on image as this:\n",
    "            X-coordinate left_ear_x-position\n",
    "            Y-coodinate (middle position of top of eye)\n",
    "     '''\n",
    "    # Calculating the sizes and position im face image\n",
    "    if left_ear_x > face_img.shape[1]:  # right ear (x-position) ouside image!\n",
    "        left_ear_x = face_img.shape[1]\n",
    "\n",
    "    image_mask_width = left_ear_x - right_ear_x\n",
    "    mask_width = mask.shape[1]\n",
    "   \n",
    "\n",
    "    mask_scale = (image_mask_width / mask_width)\n",
    " \n",
    "\n",
    "    mask_img = cv2.resize(mask, None, fx=mask_scale, fy=mask_scale)\n",
    "    y_pos = int((left_eye_center[0] + right_eye_center[0])/2) - int(mask_img.shape[0]/3)\n",
    "    x_pos = int((right_eye_center[1] + left_eye_center[1])/2)\n",
    "\n",
    "    x_pos = x_pos - int((mask_img.shape[1]/2))\n",
    "    if x_pos < 0:  # if calculatet out of bound, set to 0\n",
    "        mask_img = mask_img[:,abs(x_pos):mask_img.shape[1]] # Crop mask image in x-direction\n",
    "        x_pos = 0\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "    # trying to merge alpha channel\n",
    "    alpha_mask_img = mask_img[:, :, 3] / 255.0\n",
    "    alpha_img = 1.0 - alpha_mask_img \n",
    "\n",
    "   \n",
    "\n",
    "    # do the masking\n",
    "    return add_mask_on_image(face_img, mask_img, alpha_img,alpha_mask_img,x_pos, y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d5d2a-90d6-42c0-a3c7-58c325a27ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_cap (face_img, mask, face_landmarks):\n",
    "    \"\"\" Mask a cap on an face image\n",
    "    parameters:\n",
    "        img: face image\n",
    "        mask: occlusion\n",
    "        face_landmarks: landmarks with 68 points for the face\n",
    "    return:\n",
    "        the image with the occlusion\n",
    "    \"\"\"\n",
    "\n",
    "    # positions of the landmarks of interest\n",
    "    right_ear_x = face_landmarks.part(0).x\n",
    "    left_ear_x = face_landmarks.part(16).x\n",
    "    right_eyebrow_y = face_landmarks.part(19).y\n",
    "    left_eyebrow_y = face_landmarks.part(24).y\n",
    "    low_y = face_landmarks.part(27).y # nose root\n",
    "\n",
    "    # Calculating the sizes and position im face image\n",
    "    increase_factor = 1.15 # Increase width by 15 % to compensate for ear-position\n",
    "                             # gives a more realistic outlook\n",
    "\n",
    "    if left_ear_x > face_img.shape[1]:  # left ear (x-position) ouside image\n",
    "        left_ear_x = face_img.shape[1]\n",
    "    if right_ear_x < 0:                 # right ear positioned outside image\n",
    "        right_ear_x = 0\n",
    "\n",
    "    # scaling up the occlusion\n",
    "    image_mask_width = int((left_ear_x - right_ear_x) * increase_factor)\n",
    "    mask_width = mask.shape[1]\n",
    "    mask_scale = (image_mask_width / mask_width)\n",
    "\n",
    "    # Resize the mask for maximum x-size inf face:\n",
    "    mask_img = cv2.resize(mask, None, fx=mask_scale, fy=mask_scale)\n",
    "    cap_lower_y_position = int((low_y + (right_eyebrow_y+ left_eyebrow_y)/2)/2)\n",
    "\n",
    "    \"\"\" If the cap (now enlarged) reaches outside the face image, we have to crop the cap\n",
    "        on both ends (if neccessary) \"\"\"\n",
    "    crop_the_occlusion = False # Initially: not a need of cropping the occlusion\n",
    "    # Need of croppoing the top of the occlusion?\n",
    "    if cap_lower_y_position < mask_img.shape[0]:\n",
    "        #Cut off mask on top\n",
    "        start_pos_y = mask_img.shape[0] - cap_lower_y_position\n",
    "        crop_the_occlusion = True\n",
    "        y_pos = 0\n",
    "\n",
    "    # Need of cropping the occlusion on left and right end?\n",
    "    x_pos = int(right_ear_x - (image_mask_width*((increase_factor-1)/2)) ) # Left position Adjust by half of increase %\n",
    "    if (x_pos < 0): # lef position of image is outside the image (must cut left part)\n",
    "        start_pos_x = -(x_pos) # align the occlusion to the left edge of the face image\n",
    "        crop_the_occlusion = True\n",
    "        x_pos = 0\n",
    "    else:\n",
    "        start_pos_x = 0\n",
    "\n",
    "    x_pos_2 = int(left_ear_x + (image_mask_width*((increase_factor-1)/2)) ) # right position Adjust by half of increase %\n",
    "    if x_pos_2 > face_img.shape[1]:  # Right position of mask is outside the image\n",
    "        end_pos_x = mask_img.shape[1] -x_pos_2 + face_img.shape[1]\n",
    "        crop_the_occlusion = True\n",
    "    else:\n",
    "        end_pos_x = mask_img.shape[1]\n",
    "\n",
    "    # Need of cropping the occlusion:\n",
    "    if crop_the_occlusion:\n",
    "        # crop the mask image:\n",
    "        crop_img = mask_img[start_pos_y:mask_img.shape[0],\n",
    "                       start_pos_x:end_pos_x]\n",
    "        mask_img = crop_img.copy()\n",
    "\n",
    "    # Calculate position of the occlusion\n",
    "    y_pos = cap_lower_y_position - mask_img.shape[0]\n",
    "    image_mask_width = mask_img.shape[0]\n",
    "    # Size of the new mask\n",
    "\n",
    "    alpha_mask_img = mask_img[:, :, 3] / 255.0\n",
    "    alpha_img = 1.0 - alpha_mask_img\n",
    "\n",
    "    # occlusion masking:\n",
    "    return add_mask_on_image(\n",
    "        face_img, mask_img, alpha_img, alpha_mask_img, x_pos, y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ee551-4d86-4ae0-aa07-cc04ca00fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_face_mask (face_img, mask, face_landmarks):\n",
    "    '''\n",
    "\n",
    "    Mask a face-mask on a face image\n",
    "    parameters:\n",
    "        img: face image\n",
    "        mask: occlusion\n",
    "        face_landmarks: landmarks with 68 points for the face\n",
    "    return:\n",
    "\n",
    "        the image with the occlusion\n",
    "    '''\n",
    "      \n",
    "\n",
    "    # positions of the landmarks of interest\n",
    "    right_ear_x = face_landmarks.part(0).x\n",
    "    left_ear_x = face_landmarks.part(16).x\n",
    "    chin_y  = face_landmarks.part(8).y\n",
    "    nose_y  = face_landmarks.part(28).y\n",
    "\n",
    "    # Calculating the sizes and position im face image\n",
    "    # if left or tight ear is outside the face image, we have to adjust to edge of image\n",
    "    if left_ear_x > face_img.shape[1]:  # right ear (x-position) ouside image\n",
    "        left_ear_x = face_img.shape[1]\n",
    "    if right_ear_x < 0:\n",
    "        right_ear_x = 0\n",
    "       \n",
    "\n",
    "    image_mask_width = left_ear_x - right_ear_x\n",
    "    mask_width = mask.shape[1]\n",
    "    image_mask_height = chin_y-nose_y\n",
    "    mask_height = mask.shape[0]\n",
    "   \n",
    "\n",
    "    mask_scale_x = (image_mask_width / mask_width)\n",
    "    mask_scale_y = (image_mask_height / mask_height)\n",
    "       \n",
    "\n",
    "    resized_face_mask = cv2.resize(mask, None, fx=mask_scale_x, fy=mask_scale_y)\n",
    "    y_pos = chin_y - resized_face_mask.shape[0]\n",
    "    if chin_y > face_img.shape[0]:\n",
    "        # have to reduce the mask at bottom, while it exceeds the image size\n",
    "       resized_face_mask = resized_face_mask[0:(face_img.shape[0] - y_pos),:]\n",
    "\n",
    "          \n",
    "\n",
    "    # trying to merge alpha channel\n",
    "    alpha_mask_img = resized_face_mask[:, :, 3] / 255.0\n",
    "    alpha_img = 1.0 - alpha_mask_img\n",
    "\n",
    "\n",
    "    x_pos = right_ear_x # x-position for the mask\n",
    "   \n",
    "\n",
    "    # Mask the face:\n",
    "    return add_mask_on_image(\n",
    "        face_img, resized_face_mask, alpha_img, alpha_mask_img, x_pos, y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ff91d-a09a-4fca-893c-63e64f66b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_occ(image_list, error_message, generated_images_count):\n",
    "    '''\n",
    "    Masking in the selected occlusion(s) on the given face image\n",
    "    saves the result in the result-catalog\n",
    "    Parameters:\n",
    "        image_list : filename of all face images that are to be processed\n",
    "    The routine does the occlusion maskin for all face images in the catalog\n",
    "        (or the one given in the program)\n",
    "    The masking sequence:\n",
    "        mask, glass, cap\n",
    "    '''\n",
    "\n",
    "    # now, from the dlib we are extracting the method get_frontal_face_detector()\n",
    "    # and assign that object result to frontal_face_detector to detect face from the image with\n",
    "    # the help of the 68_face_landmarks.dat model\n",
    "    frontal_face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    # Now the dlip shape_predictor class will take model and with the help of that, it will show\n",
    "    face_landmark_detector = dlib.shape_predictor(model_path)\n",
    "\n",
    "    if glass:\n",
    "        glass_mask = cv2.imread(occ_catalogue + '/' +glass, cv2.IMREAD_UNCHANGED)\n",
    "        if glass_mask.shape[2] == 3: # Add alpha channel if not exist in image\n",
    "            glass_mask = cv2.cvtColor(glass_mask, cv2.COLOR_BGR2BGRA)\n",
    "    if mask:\n",
    "        face_mask = cv2.imread(occ_catalogue+ '/' + mask, cv2.IMREAD_UNCHANGED)\n",
    "        if face_mask.shape[2] == 3: # Add alpha channel if not exist in image\n",
    "            face_mask = cv2.cvtColor(face_mask, cv2.COLOR_BGR2BGRA)\n",
    "    if cap:\n",
    "        cap_mask = cv2.imread(occ_catalogue + '/' + cap, cv2.IMREAD_UNCHANGED)\n",
    "        if cap_mask.shape[2] == 3: # Add alpha channel if not exist in image\n",
    "            cap_mask = cv2.cvtColor(cap_mask, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    ''' For each face image filenames in the list '''\n",
    "    for image_file_name in tqdm(image_list, file=sys.stdout):\n",
    "        face_img = cv2.imread(face_image_catalogue + '/' + image_file_name, cv2.IMREAD_UNCHANGED)\n",
    "        # check the given face images\n",
    "        if isinstance(face_img, type(None)):\n",
    "            error_message.append('Image ' + image_file_name + ' is non-type.')\n",
    "            continue # skip this image, take the next one\n",
    "        if len(face_img.shape)<3: # Image content is not supported\n",
    "            error_message.append('Image ' + image_file_name + ' is not supported.')\n",
    "            continue # skip this image, take the next one\n",
    "\n",
    "        image_RGB = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "        if face_img.shape[2] == 3: # Add alpha channel if not exist in image\n",
    "            face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "        all_faces = frontal_face_detector(image_RGB, 0)\n",
    "\n",
    "        if len(all_faces) == 0:\n",
    "            error_message.append('Image ' + image_file_name +\n",
    "\n",
    "                                 ' does not contain a recognizeable face')\n",
    "            continue  # skip this image, take the next one\n",
    "        if len(all_faces) > 1:\n",
    "            error_message.append('Image ' + image_file_name +\n",
    "\n",
    "                                 ' does contain more than one face')\n",
    "            continue  # skip this image, take the next one\n",
    "\n",
    "\n",
    "        # Ready for processing the face image\n",
    "        for k in range(0, len(all_faces)):\n",
    "            # dlib rectangle class will detect faces so that landmarks can apply inside of that area\n",
    "            face_rectangle_dlib = dlib.rectangle(int(all_faces[k].left()),\n",
    "                                                 int(all_faces[k].top()),\n",
    "                                                 int(all_faces[k].right()),\n",
    "                                                 int(all_faces[k].bottom()))\n",
    "\n",
    "            # Now we are running a loop on every detected face and putting landmark on that with the help of face_landmark_detector\n",
    "            detected_landmarks = face_landmark_detector(image_RGB, face_rectangle_dlib)\n",
    "\n",
    "            # Check if the face image can be processed by this program\n",
    "            landmarks_ok, error_message = check_if_landmarks_within_image(detected_landmarks,\n",
    "\n",
    "                                                                          face_img,\n",
    "\n",
    "                                                                          image_file_name,\n",
    "\n",
    "                                                                          error_message)\n",
    "            face_from_front = check_if_face_from_front(detected_landmarks)\n",
    "            if not face_from_front:\n",
    "                error_message.append('Image ' + image_file_name +\n",
    "\n",
    "                                     ' is not taken from front. Can not process the image')\n",
    "            if not landmarks_ok or not face_from_front:\n",
    "                continue # skip this image, take the next one\n",
    "            else: # continue with next face image\n",
    "                ''' Check if the image has to be rotated '''\n",
    "                angle = rotate_face_image_angle(face_img, detected_landmarks)\n",
    "                if angle != 0: # rotating all images whit an angle != 0\n",
    "                    rotated_img = rotate_and_crop(face_img, angle, True)\n",
    "                    image_RGB = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB)\n",
    "                    if len(frontal_face_detector(image_RGB, 0)) == 0:\n",
    "                        rotated_img = rotate_and_crop(face_img, angle, False)\n",
    "                        image_RGB = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB)\n",
    "                    face_img = rotated_img.copy() # img\n",
    "\n",
    "                    # Redetect landmarks in the rotated image\n",
    "                    all_faces = frontal_face_detector(image_RGB, 0)\n",
    "                    face_rectangle_dlib = dlib.rectangle(int(all_faces[k].left()),\n",
    "                                                         int(all_faces[k].top()),\n",
    "                                                         int(all_faces[k].right()),\n",
    "                                                         int(all_faces[k].bottom()))\n",
    "                    detected_landmarks = face_landmark_detector(image_RGB,\n",
    "\n",
    "                                                                face_rectangle_dlib)\n",
    "\n",
    "                    # ...end rotated (and cropped) image...\n",
    "\n",
    "                # masking the face image with the occlusion given in the program sequence:\n",
    "                if mask:\n",
    "                    face_img = mask_face_mask(face_img, face_mask,\n",
    "\n",
    "                                              detected_landmarks)\n",
    "                if glass:\n",
    "                    face_img = mask_glasses(face_img, glass_mask,\n",
    "\n",
    "                                            detected_landmarks)\n",
    "                if cap:\n",
    "                    face_img = mask_cap(face_img, cap_mask, detected_landmarks)\n",
    "\n",
    "                print (\"Image file: \",image_file_name,  \" occ: Cap:\", cap, \" mask: \", mask, \"Glass: \", glass)\n",
    "                # prepare saving of result file:\n",
    "                ext = ''\n",
    "                if mask:\n",
    "                    ext = '_mask'\n",
    "                if glass:\n",
    "                    if glass == 'glass.png':\n",
    "                        ext = ext + '_glass'\n",
    "                    else:\n",
    "                        ext = ext + '_sunglass'\n",
    "                if cap:\n",
    "                    ext = ext + '_cap'\n",
    "\n",
    "                # prepare for saving the result file\n",
    "                file_details = os.path.splitext(image_file_name) # Get filename (without extension)\n",
    "                new_name = file_details[0] + ext\n",
    "                new_name_path = result_catalogue + '/' + new_name + file_details[1]\n",
    "                # save face images with occlusion(s)\n",
    "                cv2.imwrite(new_name_path, face_img)\n",
    "\n",
    "                # increment number of successful face image occlusion masking\n",
    "                generated_images_count += 1\n",
    "    return error_message, generated_images_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61642a26-2dc0-48b8-8281-e60a7e6f24df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_message = []\n",
    "generated_images_count = 0\n",
    "\n",
    "# Check if user has provided cataloges and model file, and if they exist\n",
    "if not (face_image_catalogue or os.path.isdir(face_image_catalogue)):\n",
    "    error_message.append('Face image catalog not found!')\n",
    "if not (occ_catalogue or os.path.isdir(occ_catalogue)):\n",
    "    error_message.append('Occlusion image catalog not found!')\n",
    "if not (result_catalogue or os.path.isdir(result_catalogue)):\n",
    "    error_message.append('Result catalog not found!')\n",
    "if not (model_path or os.path.isfile(model_path)):\n",
    "    error_message.append('Missing or not found model file!')\n",
    "\n",
    "# Check if occlusions are selected and exist\n",
    "if not (glass or mask or cap):\n",
    "    error_message.append('No occlusions selected!')\n",
    "if glass and not os.path.isfile(occ_catalogue + '/' + glass):\n",
    "    error_message.append('Occlusion file: ' + glass +\n",
    "\n",
    "                         ' does not exist in the occlusion image catalog')\n",
    "if mask and not os.path.isfile(occ_catalogue + '/' + mask):\n",
    "    error_message.append('Occlusion file: ' + mask +\n",
    "\n",
    "                         ' does not exist in the occlusion image catalog')\n",
    "if cap and not os.path.isfile(occ_catalogue + '/' + cap):\n",
    "    error_message.append('Occlusion file: ' + cap +\n",
    "\n",
    "                         ' does not exist in the occlusion image catalog')\n",
    "\n",
    "# Make a loop of all images in the image catalog\n",
    "if face_image_catalogue:\n",
    "    image_list = []\n",
    "    for file in os.listdir(face_image_catalogue):\n",
    "        # Check if file is image and not in processed before\n",
    "        if file.endswith(('.jpg','.png','.jpeg')) and not any(ext in file for ext in synthetic_file_ext):\n",
    "            image_list.append(file)\n",
    "\n",
    "    # Check if there are any face images in the selected catalog\n",
    "    if not image_list:\n",
    "        error_message.append('Can not find any genuine images (*.png, *.jpg, *.jpeg)'\n",
    "\n",
    "                             + ' in the face image catalog')\n",
    "\n",
    "\n",
    "# If no errors have occured until now, continue with the program\n",
    "if not error_message:\n",
    "    # Mask all face images with all given occlusions\n",
    "    error_message, generated_images_count = mask_occ(image_list,\n",
    "\n",
    "                                                     error_message,\n",
    "\n",
    "                                                     generated_images_count)\n",
    "    # Print the result of the program\n",
    "    print_result(error_message, generated_images_count)\n",
    "else:\n",
    "    # Print all the error messages\n",
    "    print(\"--- Run failed ---\", file=sys.stderr)\n",
    "    print(*error_message, sep=\"\\n\", file=sys.stderr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
