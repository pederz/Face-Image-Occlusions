{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcbcb5-c15f-4ab3-aa67-3443d2b579d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import dlib\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "# location of the model (path of the model).\n",
    "model_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "# catalogues (global values)\n",
    "face_image_catalogue = './samples'\n",
    "occ_catalogue = './occ'\n",
    "result_catalogue = './results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206b8ae-b776-408b-8b1e-2a04280bcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prining/log functions\n",
    "def print_run_failed(error_message):\n",
    "    '''Print the failure message when the run fails.'''\n",
    "    print('--- Run failed ---', file=sys.stderr)\n",
    "    print(*error_message, sep='\\n', file=sys.stderr)\n",
    "\n",
    "\n",
    "def print_message(error_message):\n",
    "    '''Print error messages encountered during the program execution.'''\n",
    "    if not error_message:\n",
    "        print('None errors during occlusion masking')\n",
    "    else:\n",
    "        print(f'Number of files skipped (error): {len(error_message)}')\n",
    "        print('Errors detected during program run:', file=sys.stderr)\n",
    "        print(*error_message, sep='\\n', file=sys.stderr)\n",
    "    return None\n",
    "\n",
    "\n",
    "def print_result(error_message, generated_images_count):\n",
    "    '''Print the results of the program execution.'''\n",
    "    print('Occlusion(s) added: Mask, Cap, Glass, Sunglass')\n",
    "    print(f'\\nNumber of synthetic images generated: {generated_images_count}')\n",
    "    print_message(error_message)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_with_alpha(image_path):\n",
    "    '''Load an image with an alpha channel, adding one if it doesn't exist.'''\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    if isinstance(image, type(None)):\n",
    "        return None\n",
    "    if len(image.shape)<3: # Image content is not supported\n",
    "        return None # skip this image, take the next one\n",
    "    if image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_occlusion_images(occlusion_list):\n",
    "    '''Load occlusion images from the occlusion list.'''\n",
    "    face_mask_occ = load_image_with_alpha(occlusion_list[0])\n",
    "    glass_occ = load_image_with_alpha(occlusion_list[1])\n",
    "    sunglass_occ = load_image_with_alpha(occlusion_list[2])\n",
    "    cap_occ = load_image_with_alpha(occlusion_list[3])\n",
    "    return face_mask_occ, glass_occ, sunglass_occ, cap_occ\n",
    "\n",
    "\n",
    "def check_catalogs_and_model(face_image_catalogue, occ_catalogue, model_path, error_message):\n",
    "    '''Check existence of required catalogs and model.'''\n",
    "    if not os.path.isdir(face_image_catalogue):\n",
    "        error_message.append(\n",
    "            f'Face image catalogue ({face_image_catalogue}) not found!')\n",
    "    if not os.path.isdir(occ_catalogue):\n",
    "        error_message.append(\n",
    "            f'Occlusion image catalogue ({occ_catalogue}) not found!')\n",
    "    if not os.path.isfile(model_path):\n",
    "        error_message.append(f'Model file ({model_path}) not found!')\n",
    "    return error_message\n",
    "\n",
    "\n",
    "def check_and_get_occlusion_list(occ_catalogue, error_message):\n",
    "    '''Check existence of required occlusions and return occlusion list'''\n",
    "    required_occlusions = ['mask.png', 'glass.png', 'sunglass.png', 'cap.png']\n",
    "    occlusion_list = []\n",
    "    for occ in required_occlusions:\n",
    "        if os.path.isfile(os.path.join(occ_catalogue, occ)):\n",
    "            occlusion_list.append(os.path.join(occ_catalogue, occ))\n",
    "        else:\n",
    "            error_message.append(\n",
    "                f'Occlusion file: {occ} does not exist in the occlusion image catalog')\n",
    "\n",
    "    return occlusion_list, error_message\n",
    "\n",
    "\n",
    "def get_image_list(face_image_catalogue):\n",
    "    '''Get list of face images from the catalogue, and exclude synthetic images '''\n",
    "    synthetic_file_ext = ['_glass.', '_mask.', '_cap.', '_sunglass.']\n",
    "    image_list = []\n",
    "    for image in os.listdir(face_image_catalogue):\n",
    "        if image.endswith(('.jpg', '.png', '.jpeg')) and not any(ext in image for ext in synthetic_file_ext):\n",
    "            image_list.append(os.path.join(face_image_catalogue, image))\n",
    "    return image_list\n",
    "\n",
    "\n",
    "def create_occlusion_combinations(occlusion_list):\n",
    "    '''create combinations of occlusion to be applied '''\n",
    "    occlusion_names = [os.path.basename(occ) for occ in occlusion_list]\n",
    "    occlusion_combinations = [\n",
    "        [occlusion_names[0], ''],\n",
    "        [occlusion_names[1], occlusion_names[2], ''],\n",
    "        [occlusion_names[3], '']\n",
    "    ]\n",
    "    return occlusion_combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c6b45-64ff-4bcc-8d0e-e81cb18e1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_maximal_area_rectangle_in_rotated_rectangle(width, height, angle):\n",
    "    '''Calculate the largest possible axis-aligned rectangle in a rotated rectangle.\n",
    "    Original code by coproc from Stack Overflow, but adapted for this project'''\n",
    "    if width <= 0 or height <= 0:\n",
    "      return 0,0\n",
    "\n",
    "    width_is_longer = (width >= height)\n",
    "    side_long, side_short = (width,height) if width_is_longer else (height,width)\n",
    "\n",
    "    # since the solutions for angle, -angle and 180-angle are all the same,\n",
    "    # if suffices to look at the first quadrant and the absolute values of sin,cos:\n",
    "    sin_a, cos_a = abs(math.sin(angle)), abs(math.cos(angle))\n",
    "    if side_short <= 2.*sin_a*cos_a*side_long or abs(sin_a-cos_a) < 1e-10:\n",
    "      # half constrained case: two crop corners touch the longer side,\n",
    "      #   the other two corners are on the mid-line parallel to the longer line\n",
    "      x = 0.5*side_short\n",
    "      return (x/sin_a,x/cos_a) if width_is_longer else (x/cos_a,x/sin_a)\n",
    "    else:\n",
    "      # fully constrained case: crop touches all 4 sides\n",
    "      cos_2a = cos_a*cos_a - sin_a*sin_a\n",
    "      return (width*cos_a - height*sin_a)/cos_2a, (height*cos_a - width*sin_a)/cos_2a\n",
    "\n",
    "def rotate_image_by_angle(image, angle):\n",
    "    '''Rotate the given image by \"angle\" in the range 0-360 degrees.'''\n",
    "    height, width = image.shape[:2]\n",
    "    center = (width/2, height/2)\n",
    "    rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=angle, scale=1)\n",
    "\n",
    "    return cv2.warpAffine(src=image, M=rotate_matrix, dsize=(width, height))\n",
    "\n",
    "\n",
    "def rotate_and_crop_image_by_angle(image, angle, crop):\n",
    "    '''Rotate and optionally crop the image by the given angle in degrees. '''\n",
    "    if not crop:\n",
    "        return rotate_image_by_angle(image, angle)   # rotate only\n",
    "    else:\n",
    "        optimal_width, optimal_height = calculate_maximal_area_rectangle_in_rotated_rectangle(\n",
    "           image.shape[1], image.shape[0],math.radians(angle))\n",
    "        rotated = rotate_image_by_angle(image, angle)\n",
    "        height, width, = rotated.shape[:2]\n",
    "        y1 = height//2 - int(optimal_height/2)\n",
    "        y2 = y1 + int(optimal_height)\n",
    "        x1 = width//2 - int(optimal_width/2)\n",
    "        x2 = x1 + int(optimal_width)\n",
    "\n",
    "        return rotated[y1:y2, x1:x2]\n",
    "\n",
    "\n",
    "def calculate_eye_center(face_landmarks):\n",
    "    '''Calculate the center of each eye based on all 6 eye FaceLandmarks.'''\n",
    "    r_eye_x = int(sum(face_landmarks.part(i).x for i in range(36, 42)) / 6)\n",
    "    r_eye_y = int(sum(face_landmarks.part(i).y for i in range(36, 42)) / 6)\n",
    "    l_eye_x = int(sum(face_landmarks.part(i).x for i in range(42, 48)) / 6)\n",
    "    l_eye_y = int(sum(face_landmarks.part(i).y for i in range(42, 48)) / 6)\n",
    "\n",
    "    return (r_eye_y, r_eye_x), (l_eye_y, l_eye_x)\n",
    "\n",
    "def calculate_rotation_angle_for_eye_alignment(face_landmarks):\n",
    "    '''Calculate the rotation angle of the face image for eye alignment.'''\n",
    "\n",
    "    def get_angel (a, b, c):\n",
    "        '''function calculates the angle between three 2-dimensional points a, b, and c. '''\n",
    "        ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "        #return ang + 360 if ang < 0 else ang\n",
    "        return ang\n",
    "\n",
    "    r_eye_center, l_eye_center = calculate_eye_center(\n",
    "        face_landmarks)\n",
    "    l_eye_fixed = (l_eye_center[0], r_eye_center[1])\n",
    "    return get_angel(r_eye_center, l_eye_center, l_eye_fixed)\n",
    "\n",
    "\n",
    "def rotate_and_adjust_image_and_landmarks(face_image, angle, face_detector, landmark_predictor):\n",
    "    '''Update the image and landmarks after rotating the image by the given angle.'''\n",
    "    rotated_image = rotate_and_crop_image_by_angle(face_image, angle, True)\n",
    "    image_RGB = cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # if face is not detected after cropping, rotate the image without cropping\n",
    "    if len(face_detector(image_RGB, 0)) == 0:\n",
    "        rotated_image = rotate_and_crop_image_by_angle(face_image, angle, False)\n",
    "        image_RGB = cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_image = rotated_image.copy()\n",
    "    faces = face_detector(image_RGB, 0)\n",
    "    face_rectangle_dlib = dlib.rectangle(int(faces[0].left()), int(\n",
    "        faces[0].top()), int(faces[0].right()), int(faces[0].bottom()))\n",
    "    detected_landmarks = landmark_predictor(image_RGB, face_rectangle_dlib)\n",
    "\n",
    "    return face_image, detected_landmarks\n",
    "\n",
    "\n",
    "def crop_cap_if_needed(face, cap, face_landmarks, increase_factor):\n",
    "    '''Crop the resized cap if it extends beyond the face image boundaries.'''\n",
    "    crop = False\n",
    "    l_ear_x, r_ear_x = face_landmarks.part(0).x, face_landmarks.part(16).x\n",
    "    l_eyebrow_y = face_landmarks.part(19).y\n",
    "    r_eyebrow_y = face_landmarks.part(24).y\n",
    "    nose_root_y = face_landmarks.part(27).y\n",
    "    r_ear_x = min(r_ear_x, face.shape[1])\n",
    "    l_ear_x = max(l_ear_x, 0)\n",
    "    cap_lower_y_position = int((nose_root_y + (r_eyebrow_y + l_eyebrow_y)/2)/2)\n",
    "\n",
    "    # Check top boundary\n",
    "    if cap_lower_y_position < cap.shape[0]:\n",
    "        start_pos_y = cap.shape[0] - cap_lower_y_position\n",
    "        crop = True\n",
    "\n",
    "    # Check left boundary\n",
    "    x_left = int(l_ear_x - (cap.shape[1]*((increase_factor-1)/2)))\n",
    "    if (x_left < 0):\n",
    "        start_pos_x = -(x_left)\n",
    "        crop = True\n",
    "        x_left = 0\n",
    "    else:\n",
    "        start_pos_x = 0\n",
    "\n",
    "    # Check right boundary\n",
    "    x_right = int(r_ear_x + (cap.shape[1]*((increase_factor-1)/2)))\n",
    "    if x_right > face.shape[1]:\n",
    "        end_pos_x = cap.shape[1] - x_right + face.shape[1]\n",
    "        crop = True\n",
    "    else:\n",
    "        end_pos_x = cap.shape[1]\n",
    "\n",
    "    if crop:\n",
    "        crop_cap = cap[start_pos_y:cap.shape[0],\n",
    "                       start_pos_x:end_pos_x]\n",
    "        cap = crop_cap.copy()\n",
    "    return cap, x_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce6c46-8555-47a3-a567-f7ade456e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_occlusion_on_image(image, occlusion, x, y):\n",
    "    '''Adding a occlusion on face image using alpha blending'''\n",
    "    # Create \"inv alpha' for alpha blending by subtracting norm. mask alpha from img.\n",
    "    occlusion_alpha = occlusion[:, :, 3] / 255.0\n",
    "    image_alpha = 1.0 - occlusion_alpha\n",
    "\n",
    "    for channel in range(0, 3):\n",
    "        image[y:y+occlusion.shape[0], x:x+occlusion.shape[1], channel] = (\n",
    "            occlusion_alpha\n",
    "            * occlusion[:, :, channel]\n",
    "            + image_alpha\n",
    "            * image[y:y+occlusion.shape[0], x:x+occlusion.shape[1], channel])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38277c04-58ba-4aee-b082-006ebdc5d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_landmarks_within_image(face_landmarks, image, image_filename, error_message):\n",
    "    '''Check if given landmarks are inside the image '''\n",
    "    l_ear_x, l_ear_y = face_landmarks.part(0).x, face_landmarks.part(0).y\n",
    "    r_ear_x, r_ear_y = face_landmarks.part(16).x, face_landmarks.part(16).y\n",
    "    l_eye_y, r_eye_y = face_landmarks.part(19).y, face_landmarks.part(24).y\n",
    "    chin_x, chin_y = face_landmarks.part(8).x, face_landmarks.part(8).y\n",
    "\n",
    "    if l_ear_x < 0 or l_ear_y < 0 or l_ear_x > image.shape[1] or l_ear_y > image.shape[0]:\n",
    "        error_message.append(\n",
    "            f'Image {image_filename} face Landmarks left ear is out of bounds i.e. outside the face image)')\n",
    "        return False, error_message\n",
    "    if r_ear_x < 0 or r_ear_y < 0 or r_ear_x > image.shape[1] or r_ear_y > image.shape[0]:\n",
    "        error_message.append(\n",
    "            f'Image {image_filename} face Landmarks right ear is out of bounds i.e. outside the face image)')\n",
    "        return False, error_message\n",
    "    if l_eye_y < 0 or r_eye_y < 0:\n",
    "        error_message.append(\n",
    "            f'Image {image_filename} face Landmarks eyes are out of bounds(i.e. outside the face image)')\n",
    "        return False, error_message\n",
    "    if chin_x < 0 or chin_y < 0 or chin_x > image.shape[1]:\n",
    "        error_message.append(\n",
    "            f'Image {image_filename} face Landmarks chin is out of bounds i.e. outside the face image)')\n",
    "        return False, error_message\n",
    "    return True, error_message\n",
    "\n",
    "\n",
    "def verify_frontal_face_orientation(face_landmarks, image_filename, error_message):\n",
    "    '''Verify if face image photo is taken from front'''\n",
    "    ratio = 4 # Ratio between ear and eye (left and right side)\n",
    "    r_eye_center, l_eye_center = calculate_eye_center(face_landmarks)\n",
    "    l_ear_x, r_ear_x = face_landmarks.part(0).x, face_landmarks.part(16).x\n",
    "    distance_left, distance_right = r_eye_center[1] - \\\n",
    "        l_ear_x, r_ear_x - l_eye_center[1]\n",
    "\n",
    "    if distance_left < distance_right and (distance_right / distance_left) > ratio:\n",
    "        error_message.append(\n",
    "            f'Image {image_filename} is not taken from front. Can not process the image')\n",
    "        return False, error_message\n",
    "    if distance_left > distance_right and (distance_left / distance_right) > ratio:\n",
    "        error_message.append(\n",
    "            f'Image {image_filename} is not taken from front. Can not process the image')\n",
    "        return False, error_message\n",
    "    return True, error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74e6d1-10da-4889-a5b8-c36c24679cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_glasses(face, glass, face_landmarks):\n",
    "    '''Add glass occlusion on a face image'''\n",
    "    l_ear_x, r_ear_x = face_landmarks.part(0).x, face_landmarks.part(16).x\n",
    "    r_eye_center, l_eye_center = calculate_eye_center(face_landmarks)\n",
    "    r_ear_x = min(face.shape[1], r_ear_x)\n",
    "    optimal_width = r_ear_x - l_ear_x\n",
    "    scale = (optimal_width / glass.shape[1])\n",
    "    resized_glass = cv2.resize(glass, None, fx=scale, fy=scale)\n",
    "\n",
    "    # calculate x and y position on face where glasses should be placed\n",
    "    y_pos = int(\n",
    "        ((r_eye_center[0] + l_eye_center[0]) / 2) - (resized_glass.shape[0] / 3))\n",
    "    x_pos = int(\n",
    "        ((l_eye_center[1] + r_eye_center[1]) / 2) - (resized_glass.shape[1] / 2))\n",
    "\n",
    "    if x_pos < 0: # Crop mask image in x-direction if it is out of bounds\n",
    "        resized_glass = resized_glass[:, abs(x_pos):resized_glass.shape[1]]\n",
    "        x_pos = 0\n",
    "\n",
    "    # add occlusion on image with alpha blending and calculated position\n",
    "    return add_occlusion_on_image(face, resized_glass, x_pos, y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d5d2a-90d6-42c0-a3c7-58c325a27ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cap (face, cap, face_landmarks):\n",
    "    '''Add cap occlusion on an face image'''\n",
    "    l_ear_x, r_ear_x = face_landmarks.part(0).x, face_landmarks.part(16).x\n",
    "    l_eyebrow_y = face_landmarks.part(19).y\n",
    "    r_eyebrow_y = face_landmarks.part(24).y\n",
    "    nose_root_y = face_landmarks.part(27).y\n",
    "\n",
    "    r_ear_x = min(r_ear_x, face.shape[1]) # fix r_ear_x if it is outside the image\n",
    "    l_ear_x = max(l_ear_x, 0) # fix l_ear_x if it is outside the image\n",
    "\n",
    "    increase_factor = 1.15 # 15 % width increase gives more realistic look\n",
    "    optimal_width = int((r_ear_x - l_ear_x) * increase_factor)\n",
    "    cap_scale = (optimal_width / cap.shape[1])\n",
    "\n",
    "    # Resize the mask for maximum x-size inf face:\n",
    "    resized_cap = cv2.resize(cap, None, fx=cap_scale, fy=cap_scale)\n",
    "    cap_lower_y_position = int((nose_root_y + (l_eyebrow_y + r_eyebrow_y)/2)/2)\n",
    "\n",
    "    resized_cap, x_pos = crop_cap_if_needed(\n",
    "        face, resized_cap, face_landmarks, increase_factor)\n",
    "\n",
    "    y_pos = cap_lower_y_position - resized_cap.shape[0]\n",
    "\n",
    "    # add occlusion on image with alpha blending and calculated position\n",
    "    return add_occlusion_on_image(face, resized_cap, x_pos, y_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ee551-4d86-4ae0-aa07-cc04ca00fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_face_mask(face_img, face_mask, face_landmarks):\n",
    "    '''Add cap occlusion on an face image'''\n",
    "    l_ear_x, r_ear_x = face_landmarks.part(0).x, face_landmarks.part(16).x\n",
    "    chin_y, nose_y = face_landmarks.part(8).y, face_landmarks.part(28).y\n",
    "\n",
    "    # fix r_ear_x if it is outside the image\n",
    "    r_ear_x = min(r_ear_x, face_img.shape[1]) # fix r_ear_x if it is outside the image\n",
    "    l_ear_x = max(l_ear_x, 0) # fix l_ear_x if it is outside the image\n",
    "\n",
    "    optimal_width = r_ear_x - l_ear_x\n",
    "    optimal_height = chin_y - nose_y\n",
    "\n",
    "    mask_scale_x = (optimal_width / face_mask.shape[1])\n",
    "    mask_scale_y = (optimal_height / face_mask.shape[0])\n",
    "\n",
    "    resized_face_mask = cv2.resize(face_mask, None, fx=mask_scale_x, fy=mask_scale_y)\n",
    "    y_pos = chin_y - resized_face_mask.shape[0]\n",
    "    if chin_y > face_img.shape[0]: # Crop in y direction if chin is outside image\n",
    "        resized_face_mask = resized_face_mask[0:(face_img.shape[0] - y_pos), :]\n",
    "\n",
    "    x_pos = l_ear_x # x-position for the mask\n",
    "\n",
    "    # Mask the face:\n",
    "    return add_occlusion_on_image(face_img, resized_face_mask, x_pos, y_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ff91d-a09a-4fca-893c-63e64f66b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_occluded_face_images_and_export(image_list, occlusion_list):\n",
    "    '''Add occlusions to a list of face images and save the results.'''\n",
    "    error_message = []\n",
    "    generated_images_count = 0\n",
    "\n",
    "    # Initialize dlib frontal face detector and landmark predictor\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    landmark_predictor = dlib.shape_predictor(model_path)\n",
    "\n",
    "    face_mask_occ, glass_occ, sunglass_occ, cap_occ = load_occlusion_images(\n",
    "        occlusion_list)\n",
    "\n",
    "    '''For each face image filenames in the list '''\n",
    "    for image in tqdm(image_list, file=sys.stdout, desc =\"Images processed\"):\n",
    "        #tqdm.write(f\"Downloading {image} files...\")\n",
    "        face_image = load_image_with_alpha(image)\n",
    "        image_filename = os.path.basename(image)\n",
    "        #print (\"Processing: \", image_filename)\n",
    "        # Validate images and skip if not valid\n",
    "        if isinstance(face_image, type(None)):\n",
    "            error_message.append(\n",
    "                f'Image {image_filename} cannot be read by cv2 (missing file, improper permissions, unsupported or invalid format).')\n",
    "            continue\n",
    "\n",
    "        image_RGB = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "        faces = face_detector(image_RGB, 0)\n",
    "\n",
    "        # Check for face detection issues and skip if needed\n",
    "        if len(faces) == 0:\n",
    "            error_message.append(\n",
    "                f'Image {image_filename} does not contain a recognizable face')\n",
    "            continue\n",
    "        if len(faces) > 1:\n",
    "            error_message.append(\n",
    "                f'Image {image_filename} does contain more than one face')\n",
    "            continue\n",
    "\n",
    "        # Process face bounding box and landmarks\n",
    "        face_rectangle_dlib = dlib.rectangle(int(faces[0].left()),\n",
    "                                             int(faces[0].top()),\n",
    "                                             int(faces[0].right()),\n",
    "                                             int(faces[0].bottom()))\n",
    "        detected_landmarks = landmark_predictor(image_RGB, face_rectangle_dlib)\n",
    "\n",
    "        # Validate landmarks and face orientation, skip image if not valid\n",
    "        landmarks_ok, error_message = check_if_landmarks_within_image(\n",
    "            detected_landmarks, face_image, image_filename, error_message)\n",
    "        face_from_front, error_message = verify_frontal_face_orientation(\n",
    "            detected_landmarks, image_filename, error_message)\n",
    "        if not landmarks_ok or not face_from_front:\n",
    "            continue\n",
    "\n",
    "        # Rotate the image if needed to align the face\n",
    "        angle = calculate_rotation_angle_for_eye_alignment(detected_landmarks)\n",
    "        if angle != 0:\n",
    "            face_image, detected_landmarks = rotate_and_adjust_image_and_landmarks(\n",
    "                face_image, angle, face_detector, landmark_predictor)\n",
    "\n",
    "        # Apply occlusions and save the results\n",
    "        combinations = create_occlusion_combinations(occlusion_list)\n",
    "        for mask, glass, cap in itertools.product(combinations[0], combinations[1], combinations[2]):\n",
    "            face_image_it = face_image.copy()\n",
    "            #print(f'Combinations: {mask}, {glass}, {cap}')\n",
    "            if not any([mask, glass, cap]):  # skip where no occlusion is 'selected'\n",
    "                continue\n",
    "            ext = ''\n",
    "            if mask:\n",
    "                ext += '_mask'\n",
    "                face_image_it = add_face_mask(face_image_it, face_mask_occ,\n",
    "                                           detected_landmarks)\n",
    "            if glass:\n",
    "                ext += '_glass' if glass == 'glass.png' else '_sunglass'\n",
    "                occlusion = glass_occ if glass == 'glass.png' else sunglass_occ\n",
    "                face_image_it = add_glasses(\n",
    "                    face_image_it, occlusion, detected_landmarks)\n",
    "\n",
    "            if cap:\n",
    "                ext = ext + '_cap'\n",
    "                face_image_it = add_cap(face_image_it, cap_occ, detected_landmarks)\n",
    "\n",
    "            # Saving the result image with selected occlusions\n",
    "            file_details = os.path.splitext(image_filename)\n",
    "            new_name = file_details[0] + ext\n",
    "            new_name_path = os.path.join(\n",
    "                result_catalogue, new_name + file_details[1])\n",
    "            cv2.imwrite(new_name_path, face_image_it)\n",
    "\n",
    "            #print(f'angle: {angle}')\n",
    "            # increment number of successful face image occlusion masking\n",
    "            generated_images_count += 1\n",
    "\n",
    "    # Print the result of the run\n",
    "    print_result(error_message, generated_images_count)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61642a26-2dc0-48b8-8281-e60a7e6f24df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_message = []\n",
    "\n",
    "# Validate input paths and occlusion files\n",
    "error_message = check_catalogs_and_model(\n",
    "    face_image_catalogue,\n",
    "    occ_catalogue,\n",
    "    model_path,\n",
    "    error_message\n",
    ")\n",
    "occlusion_list, error_message = check_and_get_occlusion_list(\n",
    "    occ_catalogue, error_message)\n",
    "\n",
    "if not os.path.isdir(result_catalogue):\n",
    "    os.mkdir(result_catalogue)\n",
    "\n",
    "# Get a list of face images from the provided catalog\n",
    "image_list = get_image_list(face_image_catalogue)\n",
    "if not image_list:\n",
    "    error_message.append(\n",
    "        f'Can not find any images (*.png, *.jpg, *.jpeg) in {face_image_catalogue}')\n",
    "\n",
    "# Apply combinations of occlusions to all images and print results\n",
    "if error_message:\n",
    "    print_run_failed(error_message)\n",
    "else:\n",
    "    # Apply occlusions to all face images\n",
    "    create_occluded_face_images_and_export(image_list, occlusion_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
